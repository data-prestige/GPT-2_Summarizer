{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea57a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pre_processing import cleaner_d2v\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Cleaning\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Mario\\Desktop\\Summarization_project\\video_giornalismo_dataset.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb23c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As one can notice, the title and Sottotitolo are included at the start of the description and they will be our final label\n",
    "df['description_clean'] = df.apply(lambda row : row['description'].replace(str(row['title']), ''), axis=1)\n",
    "df['description_clean'] = df.apply(lambda row : row['description_clean'].replace(str(row['Sottotitolo']), ''), axis=1)\n",
    "# Notice that we needed to remove them sequently because weird spacing occurs if title + Sottotitolo are merged first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab everything between inverted commas\n",
    "df['description_talk'] = df['description_clean'].str.findall(r'\\\"([^()]+)\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42566d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove +++ AAA Contents +++\n",
    "df['description_talk'] = df['description_clean'].str.replace(r'\\+([^()]+)\\+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112451ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put nan if empty list\n",
    "df['description_talk'] = df.description_talk.apply(lambda x: np.nan if len(x)==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From list to Series\n",
    "df['description_talk'] = df['description_talk'].apply(pd.Series).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So that we can now fill nan values with atypical description\n",
    "df['description_filled'] = df[\"description_talk\"].fillna(df[\"description_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82299770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text within brackets for ex: (Roma)... --> Roma\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "df['city'] = df['description_filled'].str.extract(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27697ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tags Uppecase as in text\n",
    "df['tags'] = df['tags'].str.upper() # all uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove city and tag\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace(str(row['city']), ''), axis=1)\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace(str(row['tags']), ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6659b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label from title and Sottotitolo\n",
    "df['label'] = df['title'] + '.' + '\\n' + df['Sottotitolo']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0fff6",
   "metadata": {},
   "source": [
    "Clean text\n",
    "df['text'] = df.description_filled.apply(lambda x: cleaner_d2v.text_cleaning(x))\n",
    "data = df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731ec53",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('\\n', ''), axis=1)\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('().', ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f04511",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace(r\"\\'\", \"'\"), axis=1)\n",
    "df['description_filled'] = df['description_filled'].str.replace(r'\\(([^()]+)\\)', '')\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('SPORT', ''), axis=1)\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('SPETTACOLO', ''), axis=1)\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('APPROFONDIMENTI', ''), axis=1)\n",
    "df['description_filled'] = df.apply(lambda row : row['description_filled'].replace('+++RIPETIZIONE CORRETTA+++', ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['description_filled', 'label']]\n",
    "data['description_filled'] = df.apply(lambda row : row['description_filled'].replace('\"', ''), axis=1)\n",
    "data['description_filled'] = data['description_filled'].str[2:]\n",
    "data['description_filled'] = data['description_filled'].replace(' ', np.NaN)\n",
    "data['description_filled'] = data['description_filled'].replace('  ', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f832568",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description_filled'].fillna(df['description'], inplace = True)\n",
    "data['description_filled'] = data.apply(lambda row : row['description_filled'].replace('\\n', ''), axis=1)\n",
    "data = data.drop(213) # dropping row 213, very weird text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c93a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write to Json tokenized txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(i,article, abstract):\n",
    "\t\"\"\" Saves a json file.\"\"\"\n",
    "\n",
    "\tfile = os.path.join(os.getcwd(), 'articoli', 'file_' + str(i) + '.json')\n",
    "\tjs_example = {}\n",
    "\tjs_example['id'] = i\n",
    "\tjs_example['article'] = article\n",
    "\tjs_example['abstract'] = abstract\n",
    "\twith open(file, 'w') as f:\n",
    "\t\tjson.dump(js_example, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d9a0b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "directory = 'articoli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26de791",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenizer_to_json(dataset, directory):\n",
    "    tokenizer = cleaner_d2v.add_special_tokens()\n",
    "    train_ids = []\n",
    "    i = 0\n",
    "    for index, row in dataset.iterrows():\n",
    "        article, abstract = tokenizer.encode(row['description_filled']), tokenizer.encode(row['label'])\n",
    "        if len(article) > 0 and len(abstract) > 0 and (len(article) + len(abstract)) <= 1023:\n",
    "        \ttrain_ids.append(i)\n",
    "        \twrite_json(i, article, abstract)\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(i, \" files written\")\n",
    "\n",
    "    file = os.path.join(os.getcwd(), directory, 'index_articoli.json')\n",
    "\n",
    "    x, y = int(len(train_ids) * 0.8), int(len(train_ids) * 0.9)\n",
    "    valid_ids = train_ids[x:y]\n",
    "    test_ids = train_ids[y:]\n",
    "    train_ids = train_ids[:x]\n",
    "    with open(file, 'w') as f:\n",
    "        js = {}\n",
    "        js['train_ids'] = train_ids\n",
    "        js['valid_ids'] = valid_ids\n",
    "        js['test_ids'] = test_ids\n",
    "        json.dump(js, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730be4b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tokenizer_to_json(dataset = data, directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567e769",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plot text length\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len_desc'] = data.description_filled.apply(lambda x: x.split(' '))\n",
    "data['len_desc'] = data.len_desc.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len_label'] = data.label.apply(lambda x: x.split(' '))\n",
    "data['len_label'] = data.len_label.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['txt_length'] = data.len_desc + data.len_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ed6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of articles sizes\n",
    "plt.hist(data['txt_length'], color='green', bins=6, edgecolor='black')\n",
    "plt.title(\"Files_Distribution_By_Size(no. of words)\")\n",
    "plt.xlabel('No Of Words')\n",
    "plt.ylabel('Files')\n",
    "plt.show()\n",
    "plt.savefig(\" files distribution by length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f364005",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train GPT-2 with GEPPETTO model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff07c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d080f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac445e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d4caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b633d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f9344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe65dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}